{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import urllib.request as ur\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1页完成\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_total = []\n",
    "for k in range(1,2):\n",
    "    ## website url we want to analysis\n",
    "    url = 'http://news.baidu.com/ns?word=%E5%85%B1%E4%BA%AB%E5%8D%95%E8%BD%A6&pn={}&cl=2&ct=1&tn=news&rn=20&ie=utf-8&bt=0&et=0'.format((k-1)*20)\n",
    "    \n",
    "    \n",
    "    \n",
    "    content1 = ur.urlopen(url).read()  # 获取网页的html文本\n",
    "    content = content1.decode('utf-8')\n",
    "    \n",
    "    # 使用BeautifulSoup解析html\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    list0 = []\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "    \n",
    "    \n",
    "    # 识别热点新闻\n",
    "    for i in range(0,20):\n",
    "        hotNews = soup.find_all('div', {'class', 'result'})[i]\n",
    "        a1 = hotNews.find(name = \"a\", attrs = {\"target\" : re.compile(\"_blank\")})\n",
    "        list0.append(a1.text)\n",
    "        a2 = hotNews.find(name = \"p\", attrs = {\"class\" : re.compile(\"c-author\")})\n",
    "        t1 = a2.text.split()[0]\n",
    "        list1.append(t1)\n",
    "        t2 = a2.text.split()[1]\n",
    "        list2.append(t2)\n",
    "        if t2.find(u'年') == 4:\n",
    "            t3 = a2.text.split()[2]\n",
    "            list3.append(t3)\n",
    "        else:\n",
    "            list3.append(' ')\n",
    "        #print list0\n",
    "    \n",
    "    #将数据写入csv\n",
    "    for i in range(0,20):\n",
    "        datatemp = { 'news' : list0[i], 'source' : list1[0], 'time' : list2[0], 'hour&minute' : list3[0]}\n",
    "        data_total.append(datatemp)\n",
    "    \n",
    "    print (u'第' + str(k) + u\"页完成\")\n",
    "    \n",
    "    \n",
    "# with open('m.csv','w',encoding = 'utf-8') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     for i in range(1,len(data_total)):\n",
    "#         writer.writerow(data_total)\n",
    "data_df = pd.DataFrame(data_total)\n",
    "data_df.to_csv('some.csv', encoding='gb18030')\n",
    "# import csv\n",
    "# with open('some.csv', 'w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(someiterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.to_csv('some2.csv',encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hour&minute': ' ',\n",
       "  'news': '“小黄车”进入昆明 ofo 共享单车覆盖城市已达26个',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '共享单车被刷成多种颜色还加私锁,运营方:已有人被拘留',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '共享单车能否熬过下个冬天',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '共享单车又添加一名“小白” 背后投资者有小米背景',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '“共享单车”离不开保驾护航',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '英媒:中国兴起自行车共享革命 意在重回两轮世界',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '借道小米和地方政府,小米生态链企业入局共享单车',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '咕咚版本又双叒叕更新 骑共享单车运动',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '共享单车被刷成多种颜色还加私锁 已有人被拘留',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '大圣归来-悟空单车拯救重庆共享单车市场',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '后互联网时代,共享单车缘何异军突起?',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '共享单车受资本热捧,详解初生行业在盲目的成长',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '新建6座过街天桥积极引进“共享单车”',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '小白单车来了 小米生态链企业骑记入局共享单车',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '深圳拟出台共享单车新规,对我们骑行有什么影响?',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '共享单车概念股火爆!哪些上市公司抢占了先机(附股)(2)',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '共享单车能否熬过下个冬天?',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '永久入局共享单车 互联网经济促传统产业转型',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '[第一时间]共享单车乱停放或被罚20元',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'},\n",
       " {'hour&minute': ' ',\n",
       "  'news': '小米生态链步局共享单车,小白单车加入单车大战',\n",
       "  'source': '网易新闻',\n",
       "  'time': '6分钟前'}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open('a.json',encoding=\"utf-8\") as data_file:    \n",
    "#     data = json.load(data_file)\n",
    "# data[0]\n",
    "data_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # -*- coding: UTF-8 -*-\n",
    "# import codecs\n",
    "# bike_data = open('some.csv','w')\n",
    "# bike_data.write(codecs.BOM_UTF8)\n",
    "# csvwriter = csv.writer(bike_data)\n",
    "# count = 0\n",
    "\n",
    "# for data_ in data:\n",
    "#     if count == 0:\n",
    "#         header_ = data_.keys()\n",
    "#         csvwriter.writerow(header_)\n",
    "#         count += 1\n",
    "#     print(data_.values())\n",
    "#     csvwriter.writerow(data_.values())\n",
    "    \n",
    "# bike_data.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.to_csv('1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 're' from 'C:\\\\Users\\\\kinsly\\\\Anaconda3\\\\lib\\\\re.py'>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
